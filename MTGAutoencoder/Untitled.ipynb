{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode_tokens: ['<START>', 'all', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      " decode_tokens: ['<START>', 'work', 'and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', '<END>', '<PAD>']\n",
      " output_tokens:['work', 'and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', '<END>', '<PAD>', '<PAD>']\n",
      "encode_tokens: ['<START>', 'all', 'work', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      " decode_tokens: ['<START>', 'and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', '<END>', '<PAD>', '<PAD>']\n",
      " output_tokens:['and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', '<END>', '<PAD>', '<PAD>', '<PAD>']\n",
      "encode_tokens: ['<START>', 'all', 'work', 'and', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      " decode_tokens: ['<START>', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', '<END>', '<PAD>', '<PAD>', '<PAD>']\n",
      " output_tokens:['no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "encode_tokens: ['<START>', 'all', 'work', 'and', 'no', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      " decode_tokens: ['<START>', 'play', 'makes', 'jack', 'a', 'dull', 'boy', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      " output_tokens:['play', 'makes', 'jack', 'a', 'dull', 'boy', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "encode_tokens: ['<START>', 'all', 'work', 'and', 'no', 'play', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      " decode_tokens: ['<START>', 'makes', 'jack', 'a', 'dull', 'boy', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      " output_tokens:['makes', 'jack', 'a', 'dull', 'boy', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "encode_tokens: ['<START>', 'all', 'work', 'and', 'no', 'play', 'makes', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      " decode_tokens: ['<START>', 'jack', 'a', 'dull', 'boy', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      " output_tokens:['jack', 'a', 'dull', 'boy', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "encode_tokens: ['<START>', 'all', 'work', 'and', 'no', 'play', 'makes', 'jack', '<END>', '<PAD>', '<PAD>', '<PAD>']\n",
      " decode_tokens: ['<START>', 'a', 'dull', 'boy', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      " output_tokens:['a', 'dull', 'boy', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "encode_tokens: ['<START>', 'all', 'work', 'and', 'no', 'play', 'makes', 'jack', 'a', '<END>', '<PAD>', '<PAD>']\n",
      " decode_tokens: ['<START>', 'dull', 'boy', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      " output_tokens:['dull', 'boy', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras_transformer import get_model\n",
    "\n",
    "# Build a small toy token dictionary\n",
    "tokens = 'all work and no play makes jack a dull boy'.split(' ')\n",
    "token_dict = {\n",
    "    '<PAD>': 0,\n",
    "    '<START>': 1,\n",
    "    '<END>': 2,\n",
    "}\n",
    "for token in tokens:\n",
    "    if token not in token_dict:\n",
    "        token_dict[token] = len(token_dict)\n",
    "\n",
    "token_dict_rev = {v: k for k, v in token_dict.items()}\n",
    "        \n",
    "# Generate toy data\n",
    "encoder_inputs_no_padding = []\n",
    "encoder_inputs, decoder_inputs, decoder_outputs = [], [], []\n",
    "for i in range(1, len(tokens) - 1):\n",
    "    encode_tokens, decode_tokens = tokens[:i], tokens[i:]\n",
    "    encode_tokens = ['<START>'] + encode_tokens + ['<END>'] + ['<PAD>'] * (len(tokens) - len(encode_tokens))\n",
    "    output_tokens = decode_tokens + ['<END>', '<PAD>'] + ['<PAD>'] * (len(tokens) - len(decode_tokens))\n",
    "    decode_tokens = ['<START>'] + decode_tokens + ['<END>'] + ['<PAD>'] * (len(tokens) - len(decode_tokens))\n",
    "    encode_tokens = list(map(lambda x: token_dict[x], encode_tokens))\n",
    "    decode_tokens = list(map(lambda x: token_dict[x], decode_tokens))\n",
    "    output_tokens = list(map(lambda x: [token_dict[x]], output_tokens))\n",
    "    encoder_inputs_no_padding.append(encode_tokens[:i + 2])\n",
    "    encoder_inputs.append(encode_tokens)\n",
    "    decoder_inputs.append(decode_tokens)\n",
    "    decoder_outputs.append(output_tokens)\n",
    "    print(f\"encode_tokens: {[token_dict_rev[i] for i in encode_tokens]}\\n decode_tokens: {[token_dict_rev[i] for i in decode_tokens]}\\n output_tokens:{[token_dict_rev[i[0]] for i in output_tokens]}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 12, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(decoder_outputs).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Nicholas\\Anaconda3_2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Nicholas\\Anaconda3_2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Nicholas\\Anaconda3_2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Nicholas\\Anaconda3_2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Nicholas\\Anaconda3_2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Nicholas\\Anaconda3_2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Nicholas\\Anaconda3_2\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Decoder-Input (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Input (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Token-Embedding (EmbeddingRet)  [(None, None, 30), ( 390         Encoder-Input[0][0]              \n",
      "                                                                 Decoder-Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Embedding (TrigPosEmbed (None, None, 30)     0           Token-Embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 30)     3720        Encoder-Embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 30)     0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 30)     0           Encoder-Embedding[0][0]          \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 30)     60          Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, None, 30)     7350        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, None, 30)     0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, None, 30)     0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, None, 30)     60          Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, None, 30)     3720        Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, None, 30)     0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, None, 30)     0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, None, 30)     60          Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, None, 30)     7350        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, None, 30)     0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, None, 30)     0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, None, 30)     60          Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, None, 30)     3720        Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, None, 30)     0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, None, 30)     0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-Embedding (TrigPosEmbed (None, None, 30)     0           Token-Embedding[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, None, 30)     60          Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadSelfAttentio (None, None, 30)     3720        Decoder-Embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, None, 30)     7350        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadSelfAttentio (None, None, 30)     0           Decoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, None, 30)     0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadSelfAttentio (None, None, 30)     0           Decoder-Embedding[0][0]          \n",
      "                                                                 Decoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, None, 30)     0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadSelfAttentio (None, None, 30)     60          Decoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, None, 30)     60          Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadQueryAttenti (None, None, 30)     3720        Decoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadQueryAttenti (None, None, 30)     0           Decoder-1-MultiHeadQueryAttention\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadQueryAttenti (None, None, 30)     0           Decoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Decoder-1-MultiHeadQueryAttention\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadQueryAttenti (None, None, 30)     60          Decoder-1-MultiHeadQueryAttention\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-FeedForward (FeedForw (None, None, 30)     7350        Decoder-1-MultiHeadQueryAttention\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-FeedForward-Dropout ( (None, None, 30)     0           Decoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-FeedForward-Add (Add) (None, None, 30)     0           Decoder-1-MultiHeadQueryAttention\n",
      "                                                                 Decoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-FeedForward-Norm (Lay (None, None, 30)     60          Decoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-2-MultiHeadSelfAttentio (None, None, 30)     3720        Decoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-2-MultiHeadSelfAttentio (None, None, 30)     0           Decoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-2-MultiHeadSelfAttentio (None, None, 30)     0           Decoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Decoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-2-MultiHeadSelfAttentio (None, None, 30)     60          Decoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-2-MultiHeadQueryAttenti (None, None, 30)     3720        Decoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-2-MultiHeadQueryAttenti (None, None, 30)     0           Decoder-2-MultiHeadQueryAttention\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-2-MultiHeadQueryAttenti (None, None, 30)     0           Decoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Decoder-2-MultiHeadQueryAttention\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-2-MultiHeadQueryAttenti (None, None, 30)     60          Decoder-2-MultiHeadQueryAttention\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-2-FeedForward (FeedForw (None, None, 30)     7350        Decoder-2-MultiHeadQueryAttention\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-2-FeedForward-Dropout ( (None, None, 30)     0           Decoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-2-FeedForward-Add (Add) (None, None, 30)     0           Decoder-2-MultiHeadQueryAttention\n",
      "                                                                 Decoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-2-FeedForward-Norm (Lay (None, None, 30)     60          Decoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-Output (EmbeddingSim)   (None, None, 13)     13          Decoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Token-Embedding[1][1]            \n",
      "==================================================================================================\n",
      "Total params: 63,913\n",
      "Trainable params: 63,523\n",
      "Non-trainable params: 390\n",
      "__________________________________________________________________________________________________\n",
      "[[4], [5], [6], [7], [8], [9], [10], [11], [12], [2], [0], [0]]\n",
      "WARNING:tensorflow:From C:\\Users\\Nicholas\\Anaconda3_2\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 0.3607\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0061\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0034\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0023\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27ea24d4588>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model\n",
    "model = get_model(\n",
    "    token_num=len(token_dict),\n",
    "    embed_dim=30,\n",
    "    encoder_num=3,\n",
    "    decoder_num=2,\n",
    "    head_num=3,\n",
    "    hidden_dim=120,\n",
    "    attention_activation='relu',\n",
    "    feed_forward_activation='relu',\n",
    "    dropout_rate=0.05,\n",
    "    embed_weights=np.random.random((13, 30)),\n",
    ")\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "print(decoder_outputs[0])\n",
    "model.fit(\n",
    "    x=[np.asarray(encoder_inputs * 1000), np.asarray(decoder_inputs * 1000)],\n",
    "    y=np.asarray(decoder_outputs * 1000),\n",
    "    epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work and no play makes jack a dull boy\n",
      "and no play makes jack a dull boy\n",
      "no play makes jack a dull boy\n",
      "play makes jack a dull boy\n",
      "makes jack a dull boy\n",
      "jack a dull boy\n",
      "a dull boy\n",
      "dull boy\n"
     ]
    }
   ],
   "source": [
    "from keras_transformer import decode\n",
    "\n",
    "decoded = decode(\n",
    "    model,\n",
    "    encoder_inputs_no_padding,\n",
    "    start_token=token_dict['<START>'],\n",
    "    end_token=token_dict['<END>'],\n",
    "    pad_token=token_dict['<PAD>'],\n",
    "    max_len=100,\n",
    ")\n",
    "\n",
    "\n",
    "test = np.asarray(decoder_outputs)\n",
    "for i in range(len(decoded)):\n",
    "    print(' '.join(map(lambda x: token_dict_rev[x], decoded[i][1:-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[4], [5], [6], [7], [8], [9], [10], [11], [12], [2], [0], [0]], [[5], [6], [7], [8], [9], [10], [11], [12], [2], [0], [0], [0]], [[6], [7], [8], [9], [10], [11], [12], [2], [0], [0], [0], [0]], [[7], [8], [9], [10], [11], [12], [2], [0], [0], [0], [0], [0]], [[8], [9], [10], [11], [12], [2], [0], [0], [0], [0], [0], [0]], [[9], [10], [11], [12], [2], [0], [0], [0], [0], [0], [0], [0]], [[10], [11], [12], [2], [0], [0], [0], [0], [0], [0], [0], [0]], [[11], [12], [2], [0], [0], [0], [0], [0], [0], [0], [0], [0]]]\n"
     ]
    }
   ],
   "source": [
    "print(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['work']\n",
      "['and']\n",
      "['no']\n",
      "['play']\n",
      "['makes']\n",
      "['jack']\n",
      "['a']\n",
      "['dull']\n",
      "['boy']\n",
      "['<END>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['and']\n",
      "['no']\n",
      "['play']\n",
      "['makes']\n",
      "['jack']\n",
      "['a']\n",
      "['dull']\n",
      "['boy']\n",
      "['<END>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['no']\n",
      "['play']\n",
      "['makes']\n",
      "['jack']\n",
      "['a']\n",
      "['dull']\n",
      "['boy']\n",
      "['<END>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['play']\n",
      "['makes']\n",
      "['jack']\n",
      "['a']\n",
      "['dull']\n",
      "['boy']\n",
      "['<END>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['makes']\n",
      "['jack']\n",
      "['a']\n",
      "['dull']\n",
      "['boy']\n",
      "['<END>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['jack']\n",
      "['a']\n",
      "['dull']\n",
      "['boy']\n",
      "['<END>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['a']\n",
      "['dull']\n",
      "['boy']\n",
      "['<END>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['dull']\n",
      "['boy']\n",
      "['<END>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n",
      "['<PAD>']\n"
     ]
    }
   ],
   "source": [
    "for i in decoder_outputs:\n",
    "    for j in i:\n",
    "        print([token_dict_rev[k] for k in j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
